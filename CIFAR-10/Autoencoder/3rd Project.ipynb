{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks and Deep Learning - 3rd Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "import time\n",
    "from keras import  layers, models, Model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, UpSampling2D, Concatenate\n",
    "\n",
    "(x1, y1), (x2, y2) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 5000  # Number of training samples\n",
    "Ntest = 10000   # Number of testing samples\n",
    "\n",
    "x1, y1 = x1[:Ntrain], y1[:Ntrain]\n",
    "x2, y2 = x2[:Ntest], y2[:Ntest]\n",
    "\n",
    "# Pixel normalization\n",
    "x1norm ,x2norm = x1/255.0, x2/255.0\n",
    "\n",
    "# Skewness, Kurtosis, Entropy of each channel and Bispectrum of grayscale images\n",
    "# !! Move the files 'train_skew_kurt_entr.npy' & 'test_skew_kurt_entr.npy' to the same folder with this code file !!\n",
    "train_stats = np.load('train_skew_kurt_entr.npy')[:Ntrain]\n",
    "test_stats = np.load('test_skew_kurt_entr.npy')[:Ntest]\n",
    "# !! Replace Path with the Paths that bispectrum excel files are !!\n",
    "bispectrum_train = pd.read_excel('C:/Users/samag/OneDrive/Υπολογιστής/9o Εξάμηνο/Neural Networks - Deep Learning/Exercises/ex1/Matlab/train_bispectrum_stats_new.xlsx')[:Ntrain]\n",
    "bispectrum_test = pd.read_excel('C:/Users/samag/OneDrive/Υπολογιστής/9o Εξάμηνο/Neural Networks - Deep Learning/Exercises/ex1/Matlab/test_bispectrum_stats_new.xlsx')[:Ntest]\n",
    "x1statistics = np.concatenate((train_stats, bispectrum_train), axis=1)\n",
    "x2statistics = np.concatenate((test_stats, bispectrum_test), axis=1)\n",
    "\n",
    "x1skew, x2skew = x1statistics[:,:3], x2statistics[:,:3]\n",
    "x1kurt, x2kurt = x1statistics[:,3:6], x2statistics[:,3:6]\n",
    "x1entr, x2entr = x1statistics[:,6:9], x2statistics[:,6:9]\n",
    "x1bispec, x2bispec = x1statistics[:,9:12], x2statistics[:,9:12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid Autoencoder (with encoder format similar to SAM12 neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Autoencoder\n",
    "\n",
    "# Encoder\n",
    "# Convolutional Part\n",
    "image_input = Input(shape=(32, 32, 3), name=\"image_input\")\n",
    "cnn_encoder = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "], name=\"cnn_encoder\")\n",
    "cnn_encoded = cnn_encoder(image_input)\n",
    "\n",
    "# MLP Part for Skeweness Features (MLP1)\n",
    "skew_input = Input(shape=(3,), name=\"skew_input\")\n",
    "skew_encoder = models.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu')\n",
    "], name=\"skew_encoder\")\n",
    "skew_encoded = skew_encoder(skew_input)\n",
    "\n",
    "# MLP Part for Kurtosis Features (MLP2)\n",
    "kurt_input = Input(shape=(3,), name=\"kurt_input\")\n",
    "kurt_encoder = models.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu')\n",
    "], name=\"kurt_encoder\")\n",
    "kurt_encoded = kurt_encoder(kurt_input)\n",
    "\n",
    "# MLP Part for Entropy Features (MLP3)\n",
    "entr_input = Input(shape=(3,), name=\"entr_input\")\n",
    "entr_encoder = models.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu')\n",
    "], name=\"entr_encoder\")\n",
    "entr_encoded = entr_encoder(entr_input)\n",
    "\n",
    "# MLP Part for Bispectrum Features (MLP4)\n",
    "bispec_input = Input(shape=(3,), name=\"bispec_input\")\n",
    "bispec_encoder = models.Sequential([\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu')\n",
    "], name=\"bispec_encoder\")\n",
    "bispec_encoded = bispec_encoder(bispec_input)\n",
    "\n",
    "# Combine Encoded Features\n",
    "combined_features = layers.concatenate(\n",
    "    [cnn_encoded, skew_encoded, kurt_encoded, entr_encoded, bispec_encoded],\n",
    "    name=\"combined_features\"\n",
    ")\n",
    "\n",
    "# Decoder\n",
    "decoder = models.Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Reshape((4, 4, 16)),\n",
    "    layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n",
    "    layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n",
    "    layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n",
    "    layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')  \n",
    "], name=\"decoder\")\n",
    "decoded_output = decoder(combined_features)\n",
    "\n",
    "# Hybrid Autoencoder Model\n",
    "hybrid_autoencoder = Model(\n",
    "    inputs=[image_input, skew_input, kurt_input, entr_input, bispec_input],\n",
    "    outputs=decoded_output,\n",
    "    name=\"hybrid_autoencoder\"\n",
    ")\n",
    "\n",
    "\n",
    "hybrid_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "hybrid_ae_st = time.time()\n",
    "history_hybrid_autoencoder =hybrid_autoencoder.fit(\n",
    "    [x1norm, x1skew, x1kurt, x1entr, x1bispec],\n",
    "    x1norm,  \n",
    "    epochs=50,\n",
    "    batch_size=128\n",
    ")\n",
    "hybrid_ae_et = time.time()\n",
    "hybrid_ae_time = hybrid_ae_et-hybrid_ae_st\n",
    "print(f\"Hybrid Autoencoder Training Time : {hybrid_ae_time:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Autoencoder \n",
    "\n",
    "image_input_simple = Input(shape=(32, 32, 3), name=\"image_input_simple\")\n",
    "\n",
    "# Encoder\n",
    "cnn_encoder_simple = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='sigmoid'),\n",
    "], name=\"cnn_encoder_simple\")\n",
    "cnn_encoded_simple = cnn_encoder_simple(image_input_simple)\n",
    "\n",
    "# Decoder\n",
    "decoder_simple = models.Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Reshape((4, 4, 16)),\n",
    "    layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n",
    "    layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n",
    "    layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same'),\n",
    "    layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same'),  \n",
    "], name=\"decoder_simple\")\n",
    "decoded_output_simple = decoder_simple(cnn_encoded_simple)\n",
    "\n",
    "\n",
    "# Convolutional Autoencoder Model\n",
    "cnn_autoencoder = Model(\n",
    "    inputs=image_input_simple,\n",
    "    outputs=decoded_output_simple,\n",
    "    name=\"cnn_autoencoder\"\n",
    ")\n",
    "\n",
    "# Compile the Convolutional Autoencoder with MSE Error (Conv AE MSE)\n",
    "cnn_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "cnn_ae_st = time.time()\n",
    "history_cnn_autoencoder = cnn_autoencoder.fit(\n",
    "    x1norm,  \n",
    "    x1norm,  \n",
    "    epochs=50,\n",
    "    batch_size=128\n",
    ")\n",
    "cnn_ae_et = time.time()\n",
    "cnn_ae_time = cnn_ae_et-cnn_ae_st\n",
    "print(f\"Convolutional Autoencoder with MSE Training Time : {cnn_ae_time:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1norm_flattened = x1norm.reshape(x1norm.shape[0], -1)  \n",
    "\n",
    "n = 0.9  \n",
    "pca = PCA(n)\n",
    "\n",
    "pca_st = time.time()\n",
    "x1norm_pca = pca.fit_transform(x1norm_flattened)\n",
    "pca_et = time.time()\n",
    "pca_time = pca_et - pca_st\n",
    "print(f\"Response Time using PCA : {pca_time:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Models with Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_reconstructed = hybrid_autoencoder.predict(\n",
    "    [x2norm, x2skew, x2kurt, x2entr, x2bispec]\n",
    ")\n",
    "\n",
    "cnn_reconstructed = cnn_autoencoder.predict(x2norm)\n",
    "\n",
    "\n",
    "x2norm_flattened = x2norm.reshape(x2norm.shape[0], -1)\n",
    "x2norm_pca = pca.transform(x2norm_flattened)\n",
    "pca_reconstructed = pca.inverse_transform(x2norm_pca)\n",
    "pca_reconstructed=pca_reconstructed.reshape(x2norm.shape)\n",
    "\n",
    "# Plot first 5 images\n",
    "num_images = 5\n",
    "fig, axes = plt.subplots(4, num_images)\n",
    "titles = [\"Original\", \"Hybrid AE\", \"Conv AE MSE\", \"PCA\"]\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Original images\n",
    "    axes[0, i].imshow(x2norm[i])\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[0, i].set_title(\"Original\")\n",
    "\n",
    "    # Hybrid AE reconstructions\n",
    "    axes[1, i].imshow(hybrid_reconstructed[i])\n",
    "    axes[1, i].axis(\"off\")\n",
    "    axes[1, i].set_title(\"Hybrid AE\")\n",
    "\n",
    "    # Conv AE reconstructions\n",
    "    axes[2, i].imshow(cnn_reconstructed[i])\n",
    "    axes[2, i].axis(\"off\")\n",
    "    axes[2, i].set_title(\"Conv AE MSE\")\n",
    "\n",
    "    # PCA reconstructions\n",
    "    axes[3, i].imshow(pca_reconstructed[i])\n",
    "    axes[3, i].axis(\"off\")\n",
    "    axes[3, i].set_title(\"PCA\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot training errors over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Hybrid AE training loss\n",
    "plt.plot(history_hybrid_autoencoder.history['loss'], label='Hybrid AE')\n",
    "\n",
    "# Conv AE training loss\n",
    "plt.plot(history_cnn_autoencoder.history['loss'], label='Conv AE MSE ')\n",
    "\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(Ntest):\n",
    "    mse_hybrid = [mean_squared_error(x2norm[i].flatten(), hybrid_reconstructed[i].flatten())]\n",
    "    mse_cnn = [mean_squared_error(x2norm[i].flatten(), cnn_reconstructed[i].flatten())]\n",
    "    mse_pca = [mean_squared_error(x2norm[i].flatten(), pca_reconstructed[i].flatten())]\n",
    "    \n",
    "# Average MSE \n",
    "avg_mse_hybrid = np.mean(mse_hybrid)\n",
    "avg_mse_cnn = np.mean(mse_cnn)\n",
    "avg_mse_pca = np.mean(mse_pca)\n",
    "\n",
    "# Average MSE Bar chart\n",
    "models = ['Hybrid AE', 'CNN AE', 'PCA']\n",
    "avg_mse_values = [avg_mse_hybrid, avg_mse_cnn, avg_mse_pca]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(models, avg_mse_values, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "plt.title('Average MSE of Reconstructed Images for Test Set')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Recontruction Models')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Avg MSE of Hybrid AE: {avg_mse_hybrid: .4f}\")\n",
    "print(f\"Avg MSE of Conv AE: {avg_mse_cnn: .4f}\")\n",
    "print(f\"Avg MSE of Reconstruction using PCA: {avg_mse_pca: .4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Autoencoder Using SSIM Loss (Conv AE SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM loss function 0 < SSIM Loss < 2 \n",
    "def ssim_loss(y_true, y_pred):\n",
    "    ssim_value = tf.image.ssim(y_true, y_pred, max_val=1.0)  \n",
    "    return 1 - tf.reduce_mean(ssim_value) \n",
    "\n",
    "\n",
    "# Convolutional Autoencoder with SSIM Loss\n",
    "cnn_autoencoder_ssim = Model(\n",
    "    inputs=image_input_simple,\n",
    "    outputs=decoded_output_simple,\n",
    "    name=\"cnn_autoencoder_ssim\"\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the Convolutional Autoencoder with SSIM Loss\n",
    "cnn_autoencoder_ssim.compile(optimizer='adam', loss=ssim_loss)\n",
    "\n",
    "\n",
    "cnn_ae_ssim_st = time.time()\n",
    "history_cnn_autoencoder_ssim = cnn_autoencoder_ssim.fit(\n",
    "    x1norm,  \n",
    "    x1norm,  \n",
    "    epochs=50,\n",
    "    batch_size=128\n",
    ")\n",
    "cnn_ae_ssim_et = time.time()\n",
    "cnn_ae_ssim_time = cnn_ae_ssim_et - cnn_ae_ssim_st\n",
    "print(f\"Convolutional Autoencoder SSIM Response Time : {cnn_ae_ssim_time:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Conv AE SSIM with Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct images using convolutional autoencoder with SSIM Loss\n",
    "cnn_reconstructed_ssim = cnn_autoencoder_ssim.predict(x2norm)\n",
    "\n",
    "num_images = 5      \n",
    "fig, axes = plt.subplots(3, num_images)\n",
    "titles = [\"Original\", \"Conv AE MSE\", \"Conv AE SSIM\"]\n",
    "\n",
    "for i in range(num_images):\n",
    "    \n",
    "    axes[0, i].imshow(x2norm[i])\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[0, i].set_title(\"Original\")\n",
    "\n",
    "   \n",
    "    axes[1, i].imshow(cnn_reconstructed[i])\n",
    "    axes[1, i].axis(\"off\")\n",
    "    axes[1, i].set_title(\"Conv AE MSE\")\n",
    "\n",
    "   \n",
    "    axes[2, i].imshow(cnn_reconstructed_ssim[i])\n",
    "    axes[2, i].axis(\"off\")\n",
    "    axes[2, i].set_title(\"Conv AE SSIM\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_cnn_autoencoder_ssim.history['loss'], label='Conv AE SSIM')\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"SSIM Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(Ntest):\n",
    "    mse_cnn = [mean_squared_error(x2norm[i].flatten(), cnn_reconstructed[i].flatten())]\n",
    "    mse_cnn_ssim = [mean_squared_error(x2norm[i].flatten(), cnn_reconstructed_ssim[i].flatten())]\n",
    "\n",
    "\n",
    "\n",
    "avg_mse_cnn = np.mean(mse_cnn)\n",
    "avg_mse_cnn_ssim = np.mean(mse_cnn_ssim)\n",
    "\n",
    "# Average MSE Bar chart\n",
    "models = ['Conv AE MSE', 'Conv AE SSIM']\n",
    "avg_mse_values = [avg_mse_cnn, avg_mse_cnn_ssim]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(models, avg_mse_values, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "plt.title('Average MSE of Reconstructed Images for Test Set')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Recontruction Models')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Avg MSE of Conv AE: {avg_mse_cnn: .4f}\")\n",
    "print(f\"Avg MSE of Conv AE SSIM: {avg_mse_cnn_ssim: .4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
